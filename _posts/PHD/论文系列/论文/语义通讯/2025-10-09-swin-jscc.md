---
layout: post
title: 'SwinJSCC: taming swin transformer for deep joint source-channel coding'
date: 2025-10-09 21:24 +0800
description: 用swin-transform结合端到端优化神经联合信源信道编码（JSCC）的方法
pin: true
math: true
mermaid: true
category: [语义通信,计算机视觉]
tags: [zotero,语义通信,计算机视觉]
published: true
sitemap: false
author: tangyu
---


* * *

## (2024-07-05) SwinJSCC: taming swin transformer for deep joint source-channel coding（）

* * *

**期刊:** （发表日期: **2024-07-05**）  
**作者:** Ke Yang; Sixian Wang; Jincheng Dai; Xiaoqi Qin; Kai Niu; Ping Zhang  
**摘要翻译:** *作为实现语义通信的关键技术之一，端到端优化神经联合信源信道编码（JSCC）在过去几年中取得了长足的进步。最近许多推动神经JSCC模型适应性或应用多样性的工作的一个总体趋势是基于卷积神经网络（CNN）骨干，其模型容量仍然有限，固有地导致与传统编码传输系统相比较差的系统编码增益。本文中，我们建立了一种新的神经JSCC骨干网，该骨干网也可以在单个模型内灵活适应不同的信道条件和传输速率，我们的开源项目旨在促进该领域的研究。具体来说，我们表明，通过精心设计，建立在新兴的Swin Transformer骨干上的神经JSCC编解码器比建立在CNN上的传统神经JSCC编码解码器具有更优的性能，同时还需要更低的端到端处理延迟。与两个基于信道状态信息和目标传输速率缩放潜在表示的空间调制模块配对，我们的基线SwinJSCC可以进一步升级到多功能版本，从而提高了其适应不同信道条件和速率配置的能力。广泛的实验结果表明，与最先进的工程BPG+5G LDPC编码传输系统相比，我们的SwinJSCC实现了更好或相当的性能，具有更快的端到端编码速度，特别是对于高分辨率图像，在这种情况下，传统的基于CNN的JSCC由于其有限的模型容量而落后。*  
**期刊分区:**  
**Local Link:** [Yang 等 - 2024 - SwinJSCC Taming Swin Transformer for Deep Joint Source-Channel Coding.pdf](zotero://open-pdf/0_PKECZN23)

* * *

> 文章先介绍了一个场景，x压缩为y，y传输yˆ，yˆ解压缩为xˆ。
>
> 采用的是x的m维压缩为y的k维，压缩方法是用CNN进行卷积，
>
> 再y的传输序列中入噪音，也就是v，用于模拟channel信道破坏，W(y,v)函数后得到实际在接收端获取的 yˆ ([pdf](zotero://open-pdf/library/items/PKECZN23?page=3)) 。这里的噪音作者采用的是高斯白噪音(AWGN)，（从高斯分布中采样），
>
> 接收端用另一个方法对其进行解压缩（可以是cnn或者其他的），得到xˆ。
>
> 最后最小化x和xˆ的差异即可。有的MSE方法和IQA（PSNR）方法，这个方法可以去检测图像质量。
>
> 前人的工作表示了SSIM比MSE有更好的改善（感知优化），所以这里采用这一系列的工作，MS-SSIM（更通用、更光的视野范围）
>
> 🔤该方法涉及将图像分解为高斯金字塔，计算每个尺度的对比度和结构相似性，以及最粗尺度的亮度相似性。在本文中，我们采用MS-SSIM，一种成熟的感知度量，作为模型训练过程中的失真函数d（·）和模型测试的IQA度量。🔤

### 有损端到端传输场景总结

1. **核心对象**：Alice 从源端获取 m 维图像向量 x，其概率分布为 px(x)。

2. **编码映射**：Alice 将 m 维向量 x 映射为 k 维向量 y（k 为信道带宽成本）。

3. **关键比率**：信道带宽比（CBR）定义为 R = k/m，通常 R < 1。

4. **传输与重构**：Alice 通过实际通信信道将 y 传输给 Bob；Bob 利用接收的信息 ŷ（y 的接收版本）重构 x 的近似值。。


代码里面确认了，就是在encoder和decoder中会共享一些确定的channel状态

[https://github.com/semcomm/SwinJSCC/](https://github.com/semcomm/SwinJSCC/)




```python
class SwinJSCC(nn.Module):
    #...
    #......
    #.........
    def forward(self, input_image, given_SNR=None, given_rate=None):
        B, _, H, W = input_image.shape

        if H != self.H or W != self.W:
            self.encoder.update_resolution(H, W)
            self.decoder.update_resolution(H // (2 ** self.downsample), W // (2 ** self.downsample))
            self.H = H
            self.W = W

        if given_SNR is None:
            SNR = choice(self.multiple_snr)
            chan_param = SNR
        else:
            chan_param = given_SNR

        if given_rate is None:
            channel_number = choice(self.channel_number)
        else:
            channel_number = given_rate

        if self.model == 'SwinJSCC_w/o_SAandRA' or self.model == 'SwinJSCC_w/_SA':
            feature = self.encoder(input_image, chan_param, channel_number, self.model)
            CBR = feature.numel() / 2 / input_image.numel()
            if self.pass_channel:
                noisy_feature = self.feature_pass_channel(feature, chan_param)
            else:
                noisy_feature = feature

        elif self.model == 'SwinJSCC_w/_RA' or self.model == 'SwinJSCC_w/_SAandRA':
            feature, mask = self.encoder(input_image, chan_param, channel_number, self.model)#与decoder公用chan_param
            #channel_number是通道数量
            CBR = channel_number / (2 * 3 * 2 ** (self.downsample * 2))
            avg_pwr = torch.sum(feature ** 2) / mask.sum()
            if self.pass_channel:
                noisy_feature = self.feature_pass_channel(feature, chan_param, avg_pwr)
            else:
                noisy_feature = feature
            noisy_feature = noisy_feature * mask  

        recon_image = self.decoder(noisy_feature, chan_param, self.model)#与encoder公用chan_param
        mse = self.squared_difference(input_image * 255., recon_image.clamp(0., 1.) * 255.)
        loss_G = self.distortion_loss.forward(input_image, recon_image.clamp(0., 1.))
        return recon_image, CBR, chan_param, mse.mean(), loss_G.mean()
```

这里的`chan_param`就是信道状态

至于target rate和rate modnet，这里引用原文的说法`This module is intended to rescale the previously proposed Channel ModNet output`

代码中写到了encoder里面

```python
class SwinJSCC_Encoder(nn.Module):
    #...
    #......
        # Channel ModNet and Rate  ModNet
	   #.........
    def forward(self, x, snr, rate, model):#这里的rate其实是channel，默认的是10，反正就是参数给的一个比例
        B, C, H, W = x.size()
        device = x.get_device()
        x = self.patch_embed(x)  #        self.patch_embed = PatchEmbed(img_size, 2, 3, embed_dims[0]) #128,3,2,2+128 embed_dims=[128, 256],img_size[32,32]
        for i_layer, layer in enumerate(self.layers):
            x = layer(x)
        x = self.norm(x)
        #...
        #......
        #.........
        elif model == 'SwinJSCC_w/_RA':
            rate_cuda = torch.tensor(rate, dtype=torch.float).to(device)
            rate_batch = rate_cuda.unsqueeze(0).expand(B, -1)
            for i in range(self.layer_num):
                if i == 0:
                    temp = self.sm_list[i](x.detach())
                else:
                    temp = self.sm_list[i](temp)

                bm = self.bm_list[i](rate_batch).unsqueeze(1).expand(-1, H * W // (self.num_layers ** 4), -1)
                temp = temp * bm
            mod_val = self.sigmoid(self.sm_list[-1](temp))
            x = x * mod_val
            mask = torch.sum(mod_val, dim=1)
            sorted, indices = mask.sort(dim=1, descending=True)
            c_indices = indices[:, :rate]
            add = torch.Tensor(range(0, B * x.size()[2], x.size()[2])).unsqueeze(1).repeat(1, rate)
            c_indices = c_indices + add.int().cuda()
            mask = torch.zeros(mask.size()).reshape(-1).cuda()
            mask[c_indices.reshape(-1)] = 1
            mask = mask.reshape(B, x.size()[2])
            mask = mask.unsqueeze(1).expand(-1, H * W // (self.num_layers ** 4), -1)
            x = x * mask
            return x, mask
        #......
          elif model == 'SwinJSCC_w/_SAandRA':
        #......
        
```



### 玻尔快读

网页版:[https://j1q.cn/HwQczk2w](https://j1q.cn/HwQczk2w)

![](/assets/md_img/202510/poster-summary251009.png)


### 💡创新点

> Tips: 本文提出了什么新的科学问题，提出了什么新的研究思路，或提出了什么新的研究工具？

### 📚前言及文献综述

> Tips: 本文的研究动机是什么？作者需要解决的问题是什么？  
> 本研究的必要性、紧迫性、可行性是什么？作者是如何论述的？  
> 作者引用了哪些该领域的开创性文献？

### 🧩数据

### 🔬方法

> 作者解决问题的方法/算法是什么？是否基于前人的方法？基于了哪些？

### 📜结论

### 🤔思考

> Tips: 本文有什么优缺点？你是否对某些内容产生了疑问？  
> 作者给出了哪些结论？哪些是strong conclusions, 哪些又是weak的conclusions（即作者并没有通过实验提供evidence，只在discussion中提到；或实验的数据并没有给出充分的evidence）?  
> 你是否认为某些研究方式可以改进，如何改进？

**模板 URL:**https://github.com/windingwind/zotero-better-notes/discussions/729

